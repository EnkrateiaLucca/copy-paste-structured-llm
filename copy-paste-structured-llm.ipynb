{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Locations with Gemini 2.0 Flash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "[\n",
      "  {\"point\": [296, 499], \"label\": \"Lucas form\"},\n",
      "  {\"point\": [393, 499], \"label\": \"Short answer text\"},\n",
      "  {\"point\": [506, 499], \"label\": \"Short answer text\"},\n",
      "  {\"point\": [619, 499], \"label\": \"Long answer text\"},\n",
      "  {\"point\": [731, 499], \"label\": \"Short answer text\"},\n",
      "  {\"point\": [844, 499], \"label\": \"Long answer text\"}\n",
      "]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "import PIL.Image\n",
    "import os\n",
    "import base64\n",
    "from io import BytesIO\n",
    "\n",
    "# Load the image\n",
    "image = PIL.Image.open('./assets/contact_form_google.png')\n",
    "\n",
    "# Convert the image to base64\n",
    "buffered = BytesIO()\n",
    "image.save(buffered, format=\"PNG\")\n",
    "image_bytes = buffered.getvalue()\n",
    "image_base64 = base64.b64encode(image_bytes).decode('utf-8')\n",
    "\n",
    "# Define the prompt\n",
    "prompt_input_forms_locations = 'Point to the locations of the input forms with no more than 10 items. The answer should follow the json format: [{\"point\": <point>, \"label\": <label1>}, ...]. The points are in [y, x] format normalized to 0-1000.'\n",
    "\n",
    "# Construct the contents list\n",
    "contents = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"parts\": [\n",
    "            {\"text\": prompt_input_forms_locations},\n",
    "            {\n",
    "                \"inlineData\": {\n",
    "                    \"mimeType\": \"image/png\",\n",
    "                    \"data\": image_base64\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Initialize the client\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "\n",
    "# Generate content\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=contents\n",
    ")\n",
    "\n",
    "# Print the response\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Points: [[296, 499], [393, 499], [506, 499], [619, 499], [731, 499], [844, 499]]\n",
      "Labels: ['Lucas form', 'Short answer text', 'Short answer text', 'Long answer text', 'Short answer text', 'Long answer text']\n",
      "Form 1: Lucas form at position [296, 499]\n",
      "Form 2: Short answer text at position [393, 499]\n",
      "Form 3: Short answer text at position [506, 499]\n",
      "Form 4: Long answer text at position [619, 499]\n",
      "Form 5: Short answer text at position [731, 499]\n",
      "Form 6: Long answer text at position [844, 499]\n"
     ]
    }
   ],
   "source": [
    "def parse_form_locations(json_output):\n",
    "    \"\"\"\n",
    "    Parse the form locations output from the model and return points and labels.\n",
    "    \n",
    "    Args:\n",
    "        json_output (str or list): Either a JSON string (possibly with markdown code blocks) \n",
    "                                  or an already parsed list of dictionaries\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Two lists containing:\n",
    "            - points: List of [y, x] coordinates\n",
    "            - labels: List of corresponding labels\n",
    "    \"\"\"\n",
    "    import json\n",
    "    import re\n",
    "    \n",
    "    # If input is a string, try to extract and parse JSON\n",
    "    if isinstance(json_output, str):\n",
    "        # Remove markdown code blocks if present\n",
    "        json_str = re.sub(r'```json\\n|\\n```', '', json_output)\n",
    "        try:\n",
    "            data = json.loads(json_str)\n",
    "        except json.JSONDecodeError as e:\n",
    "            raise ValueError(f\"Failed to parse JSON: {e}\")\n",
    "    else:\n",
    "        # Assume it's already parsed\n",
    "        data = json_output\n",
    "    \n",
    "    # Extract points and labels\n",
    "    points = []\n",
    "    labels = []\n",
    "    \n",
    "    for item in data:\n",
    "        points.append(item[\"point\"])\n",
    "        labels.append(item[\"label\"])\n",
    "    \n",
    "    return points, labels\n",
    "\n",
    "# Parse the output\n",
    "points, labels = parse_form_locations(response.text)\n",
    "\n",
    "# Print the results\n",
    "print(\"Points:\", points)\n",
    "print(\"Labels:\", labels)\n",
    "\n",
    "# You can also access specific points and labels by index\n",
    "for i, (point, label) in enumerate(zip(points, labels)):\n",
    "    print(f\"Form {i+1}: {label} at position {point}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyautogui\n",
    "import time\n",
    "\n",
    "def automate_text_input(points, texts, delay=0.5):\n",
    "    \"\"\"\n",
    "    Automatically click on specified coordinates and type text.\n",
    "    \n",
    "    Args:\n",
    "        points (list): List of [x, y] coordinates where to click\n",
    "        texts (list): List of strings to type at each coordinate\n",
    "        delay (float): Delay in seconds between actions (default: 0.5)\n",
    "    \"\"\"\n",
    "    # Safety check\n",
    "    if len(points) != len(texts):\n",
    "        raise ValueError(\"Number of points must match number of texts\")\n",
    "    \n",
    "    # Give user time to switch to the target window\n",
    "    print(\"Starting in 3 seconds... Switch to your target window!\")\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Set up pyautogui safety features\n",
    "    pyautogui.FAILSAFE = True  # Move mouse to upper-left corner to abort\n",
    "    pyautogui.PAUSE = delay    # Add delay between actions\n",
    "    \n",
    "    # Process each point and text pair\n",
    "    for (x, y), text in zip(points, texts):\n",
    "        # Move to position and click\n",
    "        pyautogui.click(x, y)\n",
    "        time.sleep(delay)  # Wait a bit after clicking\n",
    "        \n",
    "        # Type the text\n",
    "        pyautogui.write(text)\n",
    "        time.sleep(delay)  # Wait a bit after typing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Pydantic Object with the Individual Forms as Attributes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== [1] Sending screenshot to Anthropic (Claude) to produce Pydantic model ===\n",
      "from pydantic import BaseModel\n",
      "from typing import Optional\n",
      "\n",
      "class ContactInformation(BaseModel):\n",
      "    question: str\n",
      "    email: str\n",
      "    address: str\n",
      "    phone_number: Optional[str] = None\n",
      "    comments: Optional[str] = None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'form_model_20250413_145451.py' from '/Users/greatmaster/Desktop/projects/learning/copy-paste-structured-llm/form_model_20250413_145451.py.py'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import anthropic\n",
    "import re\n",
    "import importlib.util\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "MODEL_PYDANTIC_OBJECTS = \"claude-3-7-sonnet-latest\"\n",
    "anthropic_client = anthropic.Anthropic()\n",
    "\n",
    "def encode_image_to_base64(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "def extract_python_code(text):\n",
    "    \"\"\"Extract code between <python> tags\"\"\"\n",
    "    pattern = r'<python>(.*?)</python>'\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    return None\n",
    "\n",
    "def save_outputs(raw_output, extracted_code=None):\n",
    "    \"\"\"Save both raw output and extracted code to files\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Save raw output\n",
    "    raw_filename = f\"form_analysis_raw_{timestamp}.txt\"\n",
    "    with open(raw_filename, \"w\") as f:\n",
    "        f.write(raw_output)\n",
    "    print(f\"Raw output saved to: {raw_filename}\")\n",
    "    \n",
    "    # Save extracted code if available\n",
    "    if extracted_code:\n",
    "        code_filename = f\"form_model_{timestamp}.py\"\n",
    "        with open(code_filename, \"w\") as f:\n",
    "            f.write(\"from pydantic import BaseModel\\n\\n\")  # Add import statement\n",
    "            f.write(extracted_code)\n",
    "        print(f\"Extracted Pydantic model saved to: {code_filename}\")\n",
    "    \n",
    "    \n",
    "\n",
    "def call_anthropic_for_pydantic(image_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Sends a screenshot to Claude (Anthropic) with instructions:\n",
    "      - \"Create the appropriate pydantic object with the attributes for the input forms.\"\n",
    "    Returns the raw textual response from Claude, which should have <python> ... </python>.\n",
    "    \"\"\"\n",
    "    print(\"\\n=== [1] Sending screenshot to Anthropic (Claude) to produce Pydantic model ===\")\n",
    "    # The user’s custom prompt\n",
    "    prompt_message = \"\"\"\n",
    "                    Create the appropriate pydantic object with the attributes (each attribute should be of strictly type str not EmailStr nor any other special type) from this input forms page you see in front of you.\n",
    "                    Output your Python code enclosed by XML tags <python> and </python>.\n",
    "                    \"\"\"\n",
    "    img_data = encode_image_to_base64(image_path)\n",
    "\n",
    "    # Important note: This usage is conceptual. The real Anthropic Chat API\n",
    "    # might differ in usage/parameters. Adjust to your environment’s requirements.\n",
    "    # The typical chat calls are more like anthropic_client.completions.create(...)\n",
    "    # but the user’s snippet references an older \"messages.create\" approach.\n",
    "    # \n",
    "    # If your version differs, adapt accordingly.\n",
    "    message = anthropic_client.messages.create(\n",
    "        model=MODEL_PYDANTIC_OBJECTS,\n",
    "        max_tokens=1024,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"image\",\n",
    "                        \"source\": {\n",
    "                            \"type\": \"base64\",\n",
    "                            \"media_type\": \"image/png\",\n",
    "                            \"data\": img_data,\n",
    "                        },\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": prompt_message\n",
    "                    }\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    raw_output = message.content[0].text\n",
    "    return raw_output\n",
    "\n",
    "def load_dynamic_model(model_code, module_name=\"dynamic_model\"):\n",
    "    # Write code to a temporary file\n",
    "    temp_file = Path(f\"{module_name}.py\")\n",
    "    temp_file.write_text(model_code)\n",
    "    \n",
    "    # Create spec and load module\n",
    "    spec = importlib.util.spec_from_file_location(module_name, temp_file)\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    sys.modules[module_name] = module\n",
    "    spec.loader.exec_module(module)\n",
    "    \n",
    "    return module\n",
    "\n",
    "image_path = \"./assets/contact_form_google.png\"\n",
    "raw_output = call_anthropic_for_pydantic(image_path)\n",
    "extract_python_code(raw_output)\n",
    "pydantic_object = extract_python_code(raw_output)\n",
    "print(pydantic_object)\n",
    "# Usage\n",
    "module = load_dynamic_model(pydantic_object, module_name=\"form_model_20250413_145451.py\")\n",
    "module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what is the best way to learn AI?',\n",
       " 'lucas@gmail.com',\n",
       " 'X street 123',\n",
       " '2229998765',\n",
       " 'I love to program and use AI to be productive.']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "def parse_text_from_raw_input(raw_input, pydantic_object):\n",
    "    \"\"\"\n",
    "    Leverages OpenAI's API with Structured Outputs using Pydantic\n",
    "    to parse the raw input text into a Pydantic object.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Extract the structured data specified from the following text.\"},\n",
    "            {\"role\": \"user\", \"content\": raw_input}\n",
    "        ],\n",
    "        response_format=pydantic_object\n",
    "    )\n",
    "    forms_inputs = list(response.choices[0].message.parsed.__dict__.values())\n",
    "    return forms_inputs\n",
    "raw_input = \"Hi I'm Lucas my email is lucas@gmail.com and my number is 2229998765, I live in X street 123 and I love to program and use AI to be productive. question is what is the best way to learn AI?\"\n",
    "forms_inputs = parse_text_from_raw_input(raw_input, module.ContactInformation)\n",
    "forms_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>RelativeX</th>\n",
       "      <th>RelativeY</th>\n",
       "      <th>ScreenX</th>\n",
       "      <th>ScreenY</th>\n",
       "      <th>Color</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>826</td>\n",
       "      <td>572</td>\n",
       "      <td>836</td>\n",
       "      <td>607</td>\n",
       "      <td>#ff0000</td>\n",
       "      <td>2025-04-13T14:51:05.910Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>830</td>\n",
       "      <td>699</td>\n",
       "      <td>840</td>\n",
       "      <td>734</td>\n",
       "      <td>#ff0000</td>\n",
       "      <td>2025-04-13T14:51:07.133Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>824</td>\n",
       "      <td>823</td>\n",
       "      <td>834</td>\n",
       "      <td>858</td>\n",
       "      <td>#ff0000</td>\n",
       "      <td>2025-04-13T14:51:08.645Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>836</td>\n",
       "      <td>949</td>\n",
       "      <td>846</td>\n",
       "      <td>984</td>\n",
       "      <td>#ff0000</td>\n",
       "      <td>2025-04-13T14:51:09.946Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>817</td>\n",
       "      <td>1074</td>\n",
       "      <td>827</td>\n",
       "      <td>1109</td>\n",
       "      <td>#ff0000</td>\n",
       "      <td>2025-04-13T14:51:11.522Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index  RelativeX  RelativeY  ScreenX  ScreenY    Color  \\\n",
       "0      1        826        572      836      607  #ff0000   \n",
       "1      2        830        699      840      734  #ff0000   \n",
       "2      3        824        823      834      858  #ff0000   \n",
       "3      4        836        949      846      984  #ff0000   \n",
       "4      5        817       1074      827     1109  #ff0000   \n",
       "\n",
       "                  Timestamp  \n",
       "0  2025-04-13T14:51:05.910Z  \n",
       "1  2025-04-13T14:51:07.133Z  \n",
       "2  2025-04-13T14:51:08.645Z  \n",
       "3  2025-04-13T14:51:09.946Z  \n",
       "4  2025-04-13T14:51:11.522Z  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./locs.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 836,  607],\n",
       "       [ 840,  734],\n",
       "       [ 834,  858],\n",
       "       [ 846,  984],\n",
       "       [ 827, 1109]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = df[[\"ScreenX\", \"ScreenY\"]].values\n",
    "points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what is the best way to learn AI?',\n",
       " 'lucas@gmail.com',\n",
       " 'X street 123',\n",
       " '2229998765',\n",
       " 'I love to program and use AI to be productive.']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forms_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting in 3 seconds... Switch to your target window!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "automate_text_input(points, forms_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./window-screenshot.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "copy-paste-structured-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
